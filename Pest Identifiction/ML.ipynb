{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification of Agricultural Pests using ML models","metadata":{}},{"cell_type":"markdown","source":"## Extracting features from the image and storing them in an external CSV File","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport pandas as pd\nimport csv\nimport os\nfrom skimage.feature import graycomatrix, graycoprops","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:03:51.754364Z","iopub.execute_input":"2023-06-10T18:03:51.754758Z","iopub.status.idle":"2023-06-10T18:03:51.760702Z","shell.execute_reply.started":"2023-06-10T18:03:51.754729Z","shell.execute_reply":"2023-06-10T18:03:51.759324Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"inputDirectory = \"/kaggle/input/agricultural-pests-image-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:03:57.034709Z","iopub.execute_input":"2023-06-10T18:03:57.035099Z","iopub.status.idle":"2023-06-10T18:03:57.040326Z","shell.execute_reply.started":"2023-06-10T18:03:57.035065Z","shell.execute_reply":"2023-06-10T18:03:57.039149Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/features.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Image','red_sum', 'green_sum', 'blue_sum', 'correlation', 'energy', 'contrast', 'homogeneity','label'])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:06:43.359641Z","iopub.execute_input":"2023-06-10T18:06:43.360046Z","iopub.status.idle":"2023-06-10T18:06:43.367216Z","shell.execute_reply.started":"2023-06-10T18:06:43.360015Z","shell.execute_reply":"2023-06-10T18:06:43.365653Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def analyze_image(image_path):\n    # Load the image\n    image = Image.open(image_path)\n    # Convert the image to RGB mode (if it's not already)\n    image = image.convert(\"RGB\")\n    # Convert the image to a numpy array\n    image_array = np.array(image)\n\n    # Calculate the sums of colors on each channel\n    red_sum = np.sum(image_array[:, :, 0])\n    green_sum = np.sum(image_array[:, :, 1])\n    blue_sum = np.sum(image_array[:, :, 2])\n\n    # Convert the image to grayscale\n    grayscale_image = image.convert(\"L\")\n    # Convert the grayscale image to a numpy array\n    grayscale_array = np.array(grayscale_image)\n\n    # Calculate the texture properties using greycomatrix and greycoprops\n    glcm = graycomatrix(grayscale_array, distances=[1], angles=[0], symmetric=True, normed=True)\n    correlation = graycoprops(glcm, 'correlation')[0, 0]\n    energy = graycoprops(glcm, 'energy')[0, 0]\n    contrast = graycoprops(glcm, 'contrast')[0, 0]\n    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n\n    # Return the calculated features as a list\n    features = [image_array, red_sum, green_sum, blue_sum, correlation, energy, contrast, homogeneity]\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:13:03.761172Z","iopub.execute_input":"2023-06-10T18:13:03.761572Z","iopub.status.idle":"2023-06-10T18:13:03.771115Z","shell.execute_reply.started":"2023-06-10T18:13:03.761542Z","shell.execute_reply":"2023-06-10T18:13:03.770091Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for folder in os.listdir(inputDirectory):\n    print(\"Inside folder {}\".format(folder))\n    folderPath = os.path.join(inputDirectory, folder)\n    for img in os.listdir(folderPath):\n        imgPath = os.path.join(folderPath, img)\n        features = analyze_image(imgPath)\n        features.append(folder)\n        with open(\"/kaggle/working/features.csv\", 'a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow(features)\n        print(\"Processed Image: {}\".format(imgPath))","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now we have the data in CSV file to classify\n### We will load the dataset and perform data analysis and standardization","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/features.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:15:45.279432Z","iopub.execute_input":"2023-06-10T18:15:45.279817Z","iopub.status.idle":"2023-06-10T18:15:45.359204Z","shell.execute_reply.started":"2023-06-10T18:15:45.279789Z","shell.execute_reply":"2023-06-10T18:15:45.357722Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:15:49.670890Z","iopub.execute_input":"2023-06-10T18:15:49.671315Z","iopub.status.idle":"2023-06-10T18:15:49.703675Z","shell.execute_reply.started":"2023-06-10T18:15:49.671283Z","shell.execute_reply":"2023-06-10T18:15:49.702514Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                               Image   red_sum  green_sum  \\\n0  [[[119 124 128]\\n  [116 121 124]\\n  [137 138 1...   8541019    8546918   \n1  [[[240 249 255]\\n  [240 249 255]\\n  [240 249 2...  13530466   13407083   \n2  [[[237 237 235]\\n  [237 237 235]\\n  [237 237 2...  12309764   11363292   \n3  [[[ 23  44   1]\\n  [ 23  44   1]\\n  [ 23  44  ...   5571475    7941488   \n4  [[[141 178  98]\\n  [142 179  99]\\n  [143 180 1...   5733322    7479809   \n\n   blue_sum  correlation    energy    contrast  homogeneity   label  \n0   8231608     0.906282  0.012002  323.347946     0.087765  beetle  \n1  13381422     0.950554  0.191100  142.611037     0.546303  beetle  \n2  10872450     0.965044  0.063243  212.055403     0.496337  beetle  \n3   2867010     0.986970  0.043663   45.376496     0.486561  beetle  \n4   2718236     0.971701  0.032272  107.877303     0.451339  beetle  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>red_sum</th>\n      <th>green_sum</th>\n      <th>blue_sum</th>\n      <th>correlation</th>\n      <th>energy</th>\n      <th>contrast</th>\n      <th>homogeneity</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[[119 124 128]\\n  [116 121 124]\\n  [137 138 1...</td>\n      <td>8541019</td>\n      <td>8546918</td>\n      <td>8231608</td>\n      <td>0.906282</td>\n      <td>0.012002</td>\n      <td>323.347946</td>\n      <td>0.087765</td>\n      <td>beetle</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[[240 249 255]\\n  [240 249 255]\\n  [240 249 2...</td>\n      <td>13530466</td>\n      <td>13407083</td>\n      <td>13381422</td>\n      <td>0.950554</td>\n      <td>0.191100</td>\n      <td>142.611037</td>\n      <td>0.546303</td>\n      <td>beetle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[[237 237 235]\\n  [237 237 235]\\n  [237 237 2...</td>\n      <td>12309764</td>\n      <td>11363292</td>\n      <td>10872450</td>\n      <td>0.965044</td>\n      <td>0.063243</td>\n      <td>212.055403</td>\n      <td>0.496337</td>\n      <td>beetle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[[ 23  44   1]\\n  [ 23  44   1]\\n  [ 23  44  ...</td>\n      <td>5571475</td>\n      <td>7941488</td>\n      <td>2867010</td>\n      <td>0.986970</td>\n      <td>0.043663</td>\n      <td>45.376496</td>\n      <td>0.486561</td>\n      <td>beetle</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[[141 178  98]\\n  [142 179  99]\\n  [143 180 1...</td>\n      <td>5733322</td>\n      <td>7479809</td>\n      <td>2718236</td>\n      <td>0.971701</td>\n      <td>0.032272</td>\n      <td>107.877303</td>\n      <td>0.451339</td>\n      <td>beetle</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### We dont need the image column for classification and we would need to encode the label column in order to feed this data for training","metadata":{}},{"cell_type":"code","source":"df = df.drop(columns = ['Image'])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:18:36.822732Z","iopub.execute_input":"2023-06-10T18:18:36.823160Z","iopub.status.idle":"2023-06-10T18:18:36.835763Z","shell.execute_reply.started":"2023-06-10T18:18:36.823126Z","shell.execute_reply":"2023-06-10T18:18:36.834683Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:19:24.782761Z","iopub.execute_input":"2023-06-10T18:19:24.783144Z","iopub.status.idle":"2023-06-10T18:19:24.966134Z","shell.execute_reply.started":"2023-06-10T18:19:24.783115Z","shell.execute_reply":"2023-06-10T18:19:24.964939Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"xTrain, xTest, yTrain, yTest = train_test_split(df.drop(columns=['label']), df['label'], train_size=0.8, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:20:22.552404Z","iopub.execute_input":"2023-06-10T18:20:22.552807Z","iopub.status.idle":"2023-06-10T18:20:22.565259Z","shell.execute_reply.started":"2023-06-10T18:20:22.552778Z","shell.execute_reply":"2023-06-10T18:20:22.563964Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labelEncoder = LabelEncoder()\nlabelEncoder.fit(yTrain)\nprint(labelEncoder.classes_)\nyTrain = labelEncoder.transform(yTrain)\nyTest = labelEncoder.transform(yTest)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:23:00.206222Z","iopub.execute_input":"2023-06-10T18:23:00.207377Z","iopub.status.idle":"2023-06-10T18:23:00.216462Z","shell.execute_reply.started":"2023-06-10T18:23:00.207340Z","shell.execute_reply":"2023-06-10T18:23:00.215003Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['ants' 'bees' 'beetle' 'catterpillar' 'earthworms' 'earwig' 'grasshopper'\n 'moth' 'slug' 'snail' 'wasp' 'weevil']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### The numerical values in the input data need to scaled, we would use standard scaler inorder to scale the dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:26:33.695503Z","iopub.execute_input":"2023-06-10T18:26:33.695941Z","iopub.status.idle":"2023-06-10T18:26:33.701496Z","shell.execute_reply.started":"2023-06-10T18:26:33.695909Z","shell.execute_reply":"2023-06-10T18:26:33.700220Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(xTrain)\nxTrain = scaler.transform(xTrain)\nxTest = scaler.transform(xTest)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:27:41.174343Z","iopub.execute_input":"2023-06-10T18:27:41.174954Z","iopub.status.idle":"2023-06-10T18:27:41.190246Z","shell.execute_reply.started":"2023-06-10T18:27:41.174916Z","shell.execute_reply":"2023-06-10T18:27:41.189233Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Now we can feed the data to ML Model to train","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, cohen_kappa_score","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:30:56.043330Z","iopub.execute_input":"2023-06-10T18:30:56.043742Z","iopub.status.idle":"2023-06-10T18:30:56.049323Z","shell.execute_reply.started":"2023-06-10T18:30:56.043713Z","shell.execute_reply":"2023-06-10T18:30:56.048200Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Model','Accuracy','Precision','Senstivity','F1 Score','MCC Score','Kappa Coeff'])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:32:53.258608Z","iopub.execute_input":"2023-06-10T18:32:53.259195Z","iopub.status.idle":"2023-06-10T18:32:53.266361Z","shell.execute_reply.started":"2023-06-10T18:32:53.259106Z","shell.execute_reply":"2023-06-10T18:32:53.265495Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Lets test SVM Model","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:34:45.418011Z","iopub.execute_input":"2023-06-10T18:34:45.419159Z","iopub.status.idle":"2023-06-10T18:34:45.530230Z","shell.execute_reply.started":"2023-06-10T18:34:45.419122Z","shell.execute_reply":"2023-06-10T18:34:45.528954Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"modelSVC = SVC()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:36:26.000147Z","iopub.execute_input":"2023-06-10T18:36:26.000614Z","iopub.status.idle":"2023-06-10T18:36:26.005353Z","shell.execute_reply.started":"2023-06-10T18:36:26.000583Z","shell.execute_reply":"2023-06-10T18:36:26.004403Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"modelSVC.fit(xTrain, yTrain)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:36:55.992376Z","iopub.execute_input":"2023-06-10T18:36:55.993101Z","iopub.status.idle":"2023-06-10T18:36:57.317698Z","shell.execute_reply.started":"2023-06-10T18:36:55.993068Z","shell.execute_reply":"2023-06-10T18:36:57.316501Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"SVC()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"yPred = modelSVC.predict(xTest)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:38:14.067783Z","iopub.execute_input":"2023-06-10T18:38:14.068188Z","iopub.status.idle":"2023-06-10T18:38:14.400833Z","shell.execute_reply.started":"2023-06-10T18:38:14.068158Z","shell.execute_reply":"2023-06-10T18:38:14.399676Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(yTest, yPred)\nprecision = precision_score(yTest, yPred, average='micro')\nsenstivity = recall_score(yTest, yPred, average='micro')\nf1 = f1_score(yTest, yPred, average='micro')\nmcc = matthews_corrcoef(yTest, yPred)\nkappa = cohen_kappa_score(yTest, yPred)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:45:49.520586Z","iopub.execute_input":"2023-06-10T18:45:49.521041Z","iopub.status.idle":"2023-06-10T18:45:49.549039Z","shell.execute_reply.started":"2023-06-10T18:45:49.521010Z","shell.execute_reply":"2023-06-10T18:45:49.546539Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['SVM',accuracy,precision,senstivity,f1,mcc,kappa])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:47:04.609751Z","iopub.execute_input":"2023-06-10T18:47:04.610188Z","iopub.status.idle":"2023-06-10T18:47:04.617390Z","shell.execute_reply.started":"2023-06-10T18:47:04.610159Z","shell.execute_reply":"2023-06-10T18:47:04.616235Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Lets test Decision Tree Model","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodelDecisionTree = DecisionTreeClassifier()\nmodelDecisionTree.fit(xTrain, yTrain)\nyPred = modelDecisionTree.predict(xTest)\naccuracy = accuracy_score(yTest, yPred)\nprecision = precision_score(yTest, yPred, average='micro')\nsenstivity = recall_score(yTest, yPred, average='micro')\nf1 = f1_score(yTest, yPred, average='micro')\nmcc = matthews_corrcoef(yTest, yPred)\nkappa = cohen_kappa_score(yTest, yPred)\nwith open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Decision Tree',accuracy,precision,senstivity,f1,mcc,kappa])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:50:23.163904Z","iopub.execute_input":"2023-06-10T18:50:23.164393Z","iopub.status.idle":"2023-06-10T18:50:23.475103Z","shell.execute_reply.started":"2023-06-10T18:50:23.164353Z","shell.execute_reply":"2023-06-10T18:50:23.473428Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Lets Train Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodelLogisticRegression = LogisticRegression()\nmodelLogisticRegression.fit(xTrain, yTrain)\nyPred = modelLogisticRegression.predict(xTest)\naccuracy = accuracy_score(yTest, yPred)\nprecision = precision_score(yTest, yPred, average='micro')\nsenstivity = recall_score(yTest, yPred, average='micro')\nf1 = f1_score(yTest, yPred, average='micro')\nmcc = matthews_corrcoef(yTest, yPred)\nkappa = cohen_kappa_score(yTest, yPred)\nwith open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Logistic Regression',accuracy,precision,senstivity,f1,mcc,kappa])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:53:48.945754Z","iopub.execute_input":"2023-06-10T18:53:48.947093Z","iopub.status.idle":"2023-06-10T18:53:49.155039Z","shell.execute_reply.started":"2023-06-10T18:53:48.947044Z","shell.execute_reply":"2023-06-10T18:53:49.153539Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Lets test Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodelRandomForestClassifier = RandomForestClassifier()\nmodelRandomForestClassifier.fit(xTrain, yTrain)\nyPred = modelRandomForestClassifier.predict(xTest)\naccuracy = accuracy_score(yTest, yPred)\nprecision = precision_score(yTest, yPred, average='micro')\nsenstivity = recall_score(yTest, yPred, average='micro')\nf1 = f1_score(yTest, yPred, average='micro')\nmcc = matthews_corrcoef(yTest, yPred)\nkappa = cohen_kappa_score(yTest, yPred)\nwith open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Random Forest',accuracy,precision,senstivity,f1,mcc,kappa])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:57:05.281551Z","iopub.execute_input":"2023-06-10T18:57:05.281966Z","iopub.status.idle":"2023-06-10T18:57:07.117602Z","shell.execute_reply.started":"2023-06-10T18:57:05.281927Z","shell.execute_reply":"2023-06-10T18:57:07.116215Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### Lets test XGBClassifier","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nmodelXGBClassifier = XGBClassifier()\nmodelXGBClassifier.fit(xTrain, yTrain)\nyPred = modelXGBClassifier.predict(xTest)\naccuracy = accuracy_score(yTest, yPred)\nprecision = precision_score(yTest, yPred, average='micro')\nsenstivity = recall_score(yTest, yPred, average='micro')\nf1 = f1_score(yTest, yPred, average='micro')\nmcc = matthews_corrcoef(yTest, yPred)\nkappa = cohen_kappa_score(yTest, yPred)\nwith open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['XGBoost',accuracy,precision,senstivity,f1,mcc,kappa])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T18:59:06.025280Z","iopub.execute_input":"2023-06-10T18:59:06.025713Z","iopub.status.idle":"2023-06-10T18:59:12.184588Z","shell.execute_reply.started":"2023-06-10T18:59:06.025684Z","shell.execute_reply":"2023-06-10T18:59:12.183443Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Lets Test KNN Model\n","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodelKNeighborsClassifier = KNeighborsClassifier()\nmodelKNeighborsClassifier.fit(xTrain, yTrain)\nyPred = modelKNeighborsClassifier.predict(xTest)\naccuracy = accuracy_score(yTest, yPred)\nprecision = precision_score(yTest, yPred, average='micro')\nsenstivity = recall_score(yTest, yPred, average='micro')\nf1 = f1_score(yTest, yPred, average='micro')\nmcc = matthews_corrcoef(yTest, yPred)\nkappa = cohen_kappa_score(yTest, yPred)\nwith open(\"/kaggle/working/metrics.csv\", 'a', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['KNN',accuracy,precision,senstivity,f1,mcc,kappa])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T19:03:04.796983Z","iopub.execute_input":"2023-06-10T19:03:04.797431Z","iopub.status.idle":"2023-06-10T19:03:04.894035Z","shell.execute_reply.started":"2023-06-10T19:03:04.797384Z","shell.execute_reply":"2023-06-10T19:03:04.892474Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Now Lets See the model Accuracy","metadata":{}},{"cell_type":"code","source":"result = pd.read_csv(\"/kaggle/working/metrics.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T19:03:51.088864Z","iopub.execute_input":"2023-06-10T19:03:51.089239Z","iopub.status.idle":"2023-06-10T19:03:51.098060Z","shell.execute_reply.started":"2023-06-10T19:03:51.089211Z","shell.execute_reply":"2023-06-10T19:03:51.097117Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2023-06-10T19:03:53.302265Z","iopub.execute_input":"2023-06-10T19:03:53.303224Z","iopub.status.idle":"2023-06-10T19:03:53.319202Z","shell.execute_reply.started":"2023-06-10T19:03:53.303185Z","shell.execute_reply":"2023-06-10T19:03:53.317884Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                 Model  Accuracy  Precision  Senstivity  F1 Score  MCC Score  \\\n0                  SVM  0.220200   0.220200    0.220200  0.220200   0.148648   \n1        Decision Tree  0.124659   0.124659    0.124659  0.124659   0.044029   \n2  Logistic Regression  0.192903   0.192903    0.192903  0.192903   0.119376   \n3        Random Forest  0.196542   0.196542    0.196542  0.196542   0.122435   \n4              XGBoost  0.207461   0.207461    0.207461  0.207461   0.134474   \n5                  KNN  0.182894   0.182894    0.182894  0.182894   0.109594   \n\n   Kappa Coeff  \n0     0.145967  \n1     0.043994  \n2     0.116423  \n3     0.122040  \n4     0.134120  \n5     0.107940  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Senstivity</th>\n      <th>F1 Score</th>\n      <th>MCC Score</th>\n      <th>Kappa Coeff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVM</td>\n      <td>0.220200</td>\n      <td>0.220200</td>\n      <td>0.220200</td>\n      <td>0.220200</td>\n      <td>0.148648</td>\n      <td>0.145967</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Decision Tree</td>\n      <td>0.124659</td>\n      <td>0.124659</td>\n      <td>0.124659</td>\n      <td>0.124659</td>\n      <td>0.044029</td>\n      <td>0.043994</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Logistic Regression</td>\n      <td>0.192903</td>\n      <td>0.192903</td>\n      <td>0.192903</td>\n      <td>0.192903</td>\n      <td>0.119376</td>\n      <td>0.116423</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>0.196542</td>\n      <td>0.196542</td>\n      <td>0.196542</td>\n      <td>0.196542</td>\n      <td>0.122435</td>\n      <td>0.122040</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost</td>\n      <td>0.207461</td>\n      <td>0.207461</td>\n      <td>0.207461</td>\n      <td>0.207461</td>\n      <td>0.134474</td>\n      <td>0.134120</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNN</td>\n      <td>0.182894</td>\n      <td>0.182894</td>\n      <td>0.182894</td>\n      <td>0.182894</td>\n      <td>0.109594</td>\n      <td>0.107940</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}